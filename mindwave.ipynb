{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raw data from the file\n",
    "file_path = \"MW.txt\"  # Replace with actual file path\n",
    "with open(file_path, \"r\") as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Extract codes (4th column) and brainwaves (7th column onward)\n",
    "codes = []\n",
    "brainwaves = []\n",
    "\n",
    "for line in lines[1:]:  # Skip header\n",
    "    parts = line.strip().split(\"\\t\")  # Assuming tab-separated values\n",
    "    code = parts[4]  # 4th column (code)\n",
    "    brainwave_values = list(map(float, parts[6:][0].split(',')))  # 7th column to end (brainwave signals)\n",
    "    \n",
    "    codes.append(int(code))\n",
    "    brainwaves.append(brainwave_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_length = max(len(ts) for ts in brainwaves)  # Choose max length\n",
    "\n",
    "# Function to interpolate a time series to the target length\n",
    "def interpolate_timeseries(series, target_length):\n",
    "    x_old = np.linspace(0, 1, len(series))  # Original time points\n",
    "    x_new = np.linspace(0, 1, target_length)  # New time points\n",
    "    return np.interp(x_new, x_old, series).tolist()\n",
    "\n",
    "# Apply interpolation to each series\n",
    "resampled_brainwaves = [interpolate_timeseries(ts, target_length) for ts in brainwaves]\n",
    "\n",
    "print(resampled_brainwaves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (67634,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Convert to NumPy arrays\u001b[39;00m\n\u001b[0;32m      2\u001b[0m codes \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(codes)  \u001b[38;5;66;03m# String values\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m brainwave_array \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbrainwaves\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Numerical brainwave data\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Save separately\u001b[39;00m\n\u001b[0;32m      6\u001b[0m np\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcodes.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m, codes)  \u001b[38;5;66;03m# Save codes\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (67634,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "# Convert to NumPy arrays\n",
    "codes = np.array(codes)  # String values\n",
    "brainwave_array = np.array(resampled_brainwaves)  # Numerical brainwave data\n",
    "\n",
    "# Save separately\n",
    "np.save(\"codes.npy\", codes)  # Save codes\n",
    "np.save(\"brainwaves.npy\", brainwave_array)  # Save brainwave signals\n",
    "\n",
    "print(\"Brainwave data and codes saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGDataset(Dataset):\n",
    "    def __init__(self, brainwave_array, codes):\n",
    "        \"\"\"\n",
    "        Custom PyTorch Dataset for EEG data.\n",
    "        \n",
    "        Parameters:\n",
    "        - brainwave_array: NumPy array of shape (N, 1024), EEG signals\n",
    "        - codes: NumPy array of shape (N, 1), corresponding labels\n",
    "        \"\"\"\n",
    "        self.X = torch.tensor(brainwave_array, dtype=torch.float32)  # Convert to tensor\n",
    "        self.y = torch.tensor(codes, dtype=torch.long).squeeze()  # Convert to tensor, remove extra dim\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)  # Number of samples\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]  # Returns (EEG signal, code)\n",
    "\n",
    "# Load NumPy arrays\n",
    "brainwave_array = np.load(\"brainwaves.npy\")  # Shape (N, 1024)\n",
    "codes = np.load(\"codes.npy\")+1 # Shape (N, 1)\n",
    "\n",
    "# Create Dataset\n",
    "dataset = EEGDataset(brainwave_array, codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training (80%) and validation (20%) sets\n",
    "train_size = int(0.8 * len(dataset))  # 80% for training\n",
    "val_size = len(dataset) - train_size  # Remaining 20% for validation\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Create DataLoader for both training and validation datasets\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGClassifier(nn.Module):\n",
    "    def __init__(self, num_classes=11):  # You can change the number of classes\n",
    "        super(EEGClassifier, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1)  # (1, 1024) -> (32, 1024)\n",
    "        self.pool = nn.MaxPool1d(2)  # Downsample by a factor of 2\n",
    "        self.conv2 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)  # (32, 1024) -> (64, 1024)\n",
    "        self.conv3 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)  # (64, 1024) -> (128, 1024)\n",
    "        \n",
    "        self.fc1 = nn.Linear(128 * 128, 512)  # Flattened features (128 channels, downsampled size)\n",
    "        self.fc2 = nn.Linear(512, num_classes)  # Output layer for classification\n",
    "\n",
    "        self.dropout = nn.Dropout(p=0.5)  # Dropout for regularization\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)  # Add channel dimension (N, 1024) -> (N, 1, 1024)\n",
    "        \n",
    "        x = self.pool(torch.relu(self.conv1(x)))  # Conv1 + ReLU + MaxPool\n",
    "        x = self.pool(torch.relu(self.conv2(x)))  # Conv2 + ReLU + MaxPool\n",
    "        x = self.pool(torch.relu(self.conv3(x)))  # Conv3 + ReLU + MaxPool\n",
    "        \n",
    "        x = x.view(x.size(0), -1)  # Flatten (N, 128, 128) -> (N, 128*128)\n",
    "        \n",
    "        x = self.dropout(torch.relu(self.fc1(x)))  # FC1 + ReLU + Dropout\n",
    "        x = self.fc2(x)  # Output layer\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize TensorBoard\n",
    "writer = SummaryWriter('runs/EEG_classification')\n",
    "\n",
    "# Initialize the model, criterion, and optimizer\n",
    "model = EEGClassifier(num_classes=11)  # Assuming 10 classes (modify for your case)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, epochs=10):\n",
    "    model.train()\n",
    "    global_step = 0  # To keep track of steps for TensorBoard logging\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        train_loss = 0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        \n",
    "        # Training phase\n",
    "        for eeg_batch, code_batch in train_loader:\n",
    "            eeg_batch, code_batch = eeg_batch.to(device), code_batch.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(eeg_batch)  # Forward pass\n",
    "            loss = criterion(outputs, code_batch)\n",
    "            loss.backward()  # Backpropagation\n",
    "            optimizer.step()  # Optimizer step\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            train_correct += (predicted == code_batch).sum().item()\n",
    "            train_total += code_batch.size(0)\n",
    "            \n",
    "            # TensorBoard: Log every 10 steps\n",
    "            if global_step % 10 == 0:\n",
    "                writer.add_scalar('Training Loss', loss.item(), global_step)\n",
    "                writer.add_scalar('Training Accuracy', (predicted == code_batch).sum().item() / code_batch.size(0), global_step)\n",
    "                \n",
    "            global_step += 1\n",
    "        \n",
    "        # Calculate average loss and accuracy for training set\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        train_accuracy = train_correct / train_total\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for eeg_batch, code_batch in val_loader:\n",
    "                eeg_batch, code_batch = eeg_batch.to(device), code_batch.to(device)\n",
    "                outputs = model(eeg_batch)\n",
    "                loss = criterion(outputs, code_batch)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                val_correct += (predicted == code_batch).sum().item()\n",
    "                val_total += code_batch.size(0)\n",
    "                \n",
    "        # Calculate average loss and accuracy for validation set\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        val_accuracy = val_correct / val_total\n",
    "        \n",
    "        # Log to TensorBoard\n",
    "        writer.add_scalar('Validation Loss', avg_val_loss, epoch)\n",
    "        writer.add_scalar('Validation Accuracy', val_accuracy, epoch)\n",
    "        \n",
    "        # Print results\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}]\")\n",
    "        print(f\"Train Loss: {avg_train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}\")\n",
    "        print(f\"Validation Loss: {avg_val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
    "    \n",
    "    writer.close()  # Close the TensorBoard writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(model, train_loader, val_loader, epochs=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
