{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from scipy.signal import iirnotch, filtfilt, butter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raw data from the file\n",
    "file_path = \"MW.txt\"  # Replace with actual file path\n",
    "with open(file_path, \"r\") as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Extract codes (4th column) and brainwaves (7th column onward)\n",
    "codes = []\n",
    "brainwaves = []\n",
    "\n",
    "for line in lines[1:]:  # Skip header\n",
    "    parts = line.strip().split(\"\\t\")  # Assuming tab-separated values\n",
    "    code = parts[4]  # 4th column (code)\n",
    "    brainwave_values = list(map(float, parts[6:][0].split(',')))  # 7th column to end (brainwave signals)\n",
    "    \n",
    "    codes.append(int(code))\n",
    "    brainwaves.append(brainwave_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_length = max(len(ts) for ts in brainwaves)  # Choose max length\n",
    "\n",
    "# Function to interpolate a time series to the target length\n",
    "def interpolate_timeseries(series, target_length):\n",
    "    x_old = np.linspace(0, 1, len(series))  # Original time points\n",
    "    x_new = np.linspace(0, 1, target_length)  # New time points\n",
    "    return np.interp(x_new, x_old, series).tolist()\n",
    "\n",
    "# Apply interpolation to each series\n",
    "resampled_brainwaves = [interpolate_timeseries(ts, target_length) for ts in brainwaves]\n",
    "\n",
    "print(resampled_brainwaves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to NumPy arrays\n",
    "codes = np.array(codes)  # String values\n",
    "brainwave_array = np.array(resampled_brainwaves)  # Numerical brainwave data\n",
    "\n",
    "# Save separately\n",
    "np.save(\"codes.npy\", codes)  # Save codes\n",
    "np.save(\"brainwaves.npy\", brainwave_array)  # Save brainwave signals\n",
    "\n",
    "print(\"Brainwave data and codes saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "    nyquist = 0.5 * fs\n",
    "    low = lowcut / nyquist\n",
    "    high = highcut / nyquist\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    return filtfilt(b, a, data)\n",
    "\n",
    "def notch_filter(data, fs, notch_freq=50.0, quality_factor=30.0):\n",
    "    b, a = iirnotch(notch_freq, quality_factor, fs)\n",
    "    return filtfilt(b, a, data)\n",
    "\n",
    "def filter_digit_set(waves, fs=256):\n",
    "    data = notch_filter(waves, fs)\n",
    "    data = bandpass_filter(waves, lowcut=1.0, highcut=40.0, fs=fs)\n",
    "    return data\n",
    "\n",
    "def smooth(waves, std):\n",
    "    smooth_waves = gaussian_filter1d(waves, sigma=std, radius=1024)\n",
    "    return smooth_waves, std\n",
    "\n",
    "def preprocess_digit_class(brainwaves, codes, digit_code):\n",
    "    digit_idx = np.where(codes == digit_code)\n",
    "    digit_signals = brainwaves[digit_idx]\n",
    "\n",
    "    train_size = int(0.8 * len(digit_signals))  \n",
    "    val_size = len(digit_signals) - train_size\n",
    "    train_waves, val_waves = random_split(digit_signals, [train_size, val_size])\n",
    "    \n",
    "    train_waves_filtered = filter_digit_set(train_waves)\n",
    "    val_waves_filtered = filter_digit_set(val_waves)\n",
    "\n",
    "    std = np.std(train_waves_filtered)\n",
    "\n",
    "    train_waves_filtered_smooth, std = smooth(train_waves_filtered, std)\n",
    "    val_waves_filtered_smooth, _ = smooth(val_waves_filtered, std)\n",
    "\n",
    "    train_codes = [digit_code] * len(train_waves_filtered_smooth)\n",
    "    val_codes = [digit_code] * len(val_waves_filtered_smooth)\n",
    "\n",
    "    return (train_waves_filtered_smooth, \n",
    "            val_waves_filtered_smooth,\n",
    "            train_codes,\n",
    "            val_codes)\n",
    "\n",
    "def preprocess_all_digits(brainwaves, codes):\n",
    "    digit_data = {}\n",
    "    for digit_code in range(10):  # Assuming digits 0-9\n",
    "        train_waves, val_waves, train_codes, val_codes = preprocess_digit_class(brainwaves, codes, digit_code)\n",
    "        digit_data[digit_code] = {\n",
    "            'train': (train_waves, train_codes),\n",
    "            'val': (val_waves, val_codes)\n",
    "        }\n",
    "    return digit_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load NumPy arrays\n",
    "brainwave_array = np.load(\"brainwaves.npy\")  # Shape (N, 1024)\n",
    "codes = np.load(\"codes.npy\") # Shape (N, 1)\n",
    "\n",
    "digit_code_index = np.where(codes != 0)\n",
    "non_zero_codes = codes[digit_code_index]\n",
    "non_zero_codes -= 1\n",
    "\n",
    "non_zero_brainwaves_array = brainwave_array[digit_code_index]\n",
    "\n",
    "digit_data = preprocess_all_digits(non_zero_brainwaves_array, non_zero_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All train and validation sets combined successfully!\n"
     ]
    }
   ],
   "source": [
    "# Combine all train and val sets in digit_data\n",
    "all_train_waves = []\n",
    "all_train_codes = []\n",
    "all_val_waves = []\n",
    "all_val_codes = []\n",
    "\n",
    "for digit_code, data in digit_data.items():\n",
    "    train_waves, train_codes = data['train']\n",
    "    val_waves, val_codes = data['val']\n",
    "    \n",
    "    all_train_waves.extend(train_waves)\n",
    "    all_train_codes.extend(train_codes)\n",
    "    all_val_waves.extend(val_waves)\n",
    "    all_val_codes.extend(val_codes)\n",
    "\n",
    "# Convert to NumPy arrays\n",
    "train_waves = np.array(all_train_waves)\n",
    "train_codes = np.array(all_train_codes)\n",
    "val_waves = np.array(all_val_waves)\n",
    "val_codes = np.array(all_val_codes)\n",
    "\n",
    "print(\"All train and validation sets combined successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGDataset(Dataset):\n",
    "    def __init__(self, brainwave_array, codes):\n",
    "        \"\"\"\n",
    "        Custom PyTorch Dataset for EEG data.\n",
    "        \n",
    "        Parameters:\n",
    "        - brainwave_array: NumPy array of shape (N, 1024), EEG signals\n",
    "        - codes: NumPy array of shape (N, 1), corresponding labels\n",
    "        \"\"\"\n",
    "        self.X = torch.tensor(brainwave_array, dtype=torch.float32)  # Convert to tensor\n",
    "        self.y = torch.tensor(codes, dtype=torch.long).squeeze()  # Convert to tensor, remove extra dim\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)  # Number of samples\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]  # Returns (EEG signal, code)\n",
    "\n",
    "# def normalize_data(data):\n",
    "#     return (data - data.mean(axis=1, keepdims=True)) / data.std(axis=1, keepdims=True)\n",
    "\n",
    "# def preprocess_eeg(data, fs):\n",
    "#     # Step 1: Apply Notch filter to remove 50/60Hz line noise\n",
    "#     data = notch_filter(data, fs)\n",
    "    \n",
    "#     # Step 2: Apply Bandpass filter to focus on desired frequency range (e.g., 1-40Hz)\n",
    "#     data = bandpass_filter(data, lowcut=1.0, highcut=40.0, fs=fs)\n",
    "    \n",
    "#     # Step 4: Z-score normalize data if necessary to reduce baseline drift\n",
    "#     smoothed_signal = gaussian_filter1d(data, sigma=1, radius=512)\n",
    "    \n",
    "#     return smoothed_signal\n",
    "\n",
    "# # Load NumPy arrays\n",
    "# brainwave_array = np.load(\"brainwaves.npy\")  # Shape (N, 1024)\n",
    "# codes = np.load(\"codes.npy\") # Shape (N, 1)\n",
    "\n",
    "# digit_code_index = np.where(codes != 0)\n",
    "# non_zero_codes = codes[digit_code_index]\n",
    "# non_zero_codes -= 1\n",
    "\n",
    "# normalized_brainwave_array = preprocess_eeg(brainwave_array, fs=256)  # Assuming 256Hz sampling rate\n",
    "# non_zero_brainwaves_array = normalized_brainwave_array[digit_code_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dataset\n",
    "train_dataset = EEGDataset(train_waves, train_codes)\n",
    "val_dataset = EEGDataset(val_waves, val_codes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separating classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Split the dataset into training (80%) and validation (20%) sets\n",
    "# train_size = int(0.8 * len(dataset))  # 80% for training\n",
    "# val_size = len(dataset) - train_size  # Remaining 20% for validation\n",
    "# train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Create DataLoader for both training and validation datasets\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class FFTTransform(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(FFTTransform, self).__init__()\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = torch.fft.rfft(x, dim=1)\n",
    "#         return torch.abs(x)\n",
    "\n",
    "# class EEGClassifier(nn.Module):\n",
    "#     def __init__(self, num_classes=11):\n",
    "#         super(EEGClassifier, self).__init__()\n",
    "\n",
    "#         self.conv1 = nn.Conv1d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "#         self.pool = nn.MaxPool1d(2)\n",
    "#         self.conv2 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "#         self.conv3 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "#         self.dropout = nn.Dropout(0.5)\n",
    "#         self.fc1 = nn.Linear(128 * 64, 256)  # Adjust based on final conv shape\n",
    "#         self.fc2 = nn.Linear(256, num_classes)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = x.unsqueeze(1)  # (N, 513) -> (N, 1, 513)\n",
    "\n",
    "#         x = self.pool(torch.relu(self.conv1(x)))  # (N, 1, 513) -> (N, 32, 256)\n",
    "#         x = self.pool(torch.relu(self.conv2(x)))  # (N, 32, 256) -> (N, 64, 128)\n",
    "#         x = self.pool(torch.relu(self.conv3(x)))  # (N, 64, 128) -> (N, 128, 64)\n",
    "\n",
    "#         x = x.view(x.size(0), -1)  # Flatten\n",
    "#         x = self.dropout(torch.relu(self.fc1(x)))\n",
    "#         x = self.fc2(x)\n",
    "#         return x\n",
    "\n",
    "# model = nn.Sequential(\n",
    "#     FFTTransform(),\n",
    "#     EEGClassifier(num_classes=len(np.unique(codes)))\n",
    "#     )\n",
    "\n",
    "# class EEGClassifier(nn.Module):\n",
    "#     def __init__(self, num_classes=11):  # You can change the number of classes\n",
    "#         super(EEGClassifier, self).__init__()\n",
    "        \n",
    "#         self.conv1 = nn.Conv1d(in_channels=1, out_channels=8, kernel_size=64, stride=1, padding=1)  # (1, 1024) -> (32, 1024)\n",
    "#         self.pool = nn.MaxPool1d(2)  # Downsample by a factor of 2\n",
    "#         self.conv2 = nn.Conv1d(in_channels=8, out_channels=16, kernel_size=32, stride=1, padding=1)  # (32, 1024) -> (64, 1024)\n",
    "#         self.conv3 = nn.Conv1d(in_channels=16, out_channels=32, kernel_size=16, stride=1, padding=1)  # (64, 1024) -> (128, 1024)\n",
    "        \n",
    "#         self.fc1 = nn.Linear(32 * 128, 128)  # Flattened features (128 channels, downsampled size)\n",
    "#         self.fc2 = nn.Linear(128, num_classes)  # Output layer for classification\n",
    "\n",
    "#         self.dropout = nn.Dropout(p=0.5)  # Dropout for regularization\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = x.unsqueeze(1)  # Add channel dimension (N, 1024) -> (N, 1, 1024)\n",
    "        \n",
    "#         x = self.pool(torch.relu(self.conv1(x)))  # Conv1 + ReLU + MaxPool\n",
    "#         x = self.pool(torch.relu(self.conv2(x)))  # Conv2 + ReLU + MaxPool\n",
    "#         x = self.pool(torch.relu(self.conv3(x)))  # Conv3 + ReLU + MaxPool\n",
    "        \n",
    "#         x = x.view(x.size(0), -1)  # Flatten (N, 128, 128) -> (N, 128*128)\n",
    "        \n",
    "#         x = self.dropout(torch.relu(self.fc1(x)))  # FC1 + ReLU + Dropout\n",
    "#         x = self.fc2(x)  # Output layer\n",
    "#         return x\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "class EEGClassifier(nn.Module):\n",
    "    def __init__(self, num_classes=11):  # You can change the number of classes\n",
    "        super(EEGClassifier, self).__init__()\n",
    "        \n",
    "        # First convolution layer: (1, 1024) -> (8, 1024)\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=8, kernel_size=3, stride=2, padding=1)\n",
    "        # Second convolution layer: (8, 1024) -> (16, 1024)\n",
    "        self.conv2 = nn.Conv1d(in_channels=8, out_channels=16, kernel_size=3, stride=2, padding=1)\n",
    "        # Third convolution layer: (16, 1024) -> (32, 1024)\n",
    "        self.conv3 = nn.Conv1d(in_channels=16, out_channels=32, kernel_size=3, stride=2, padding=1)\n",
    "        # Fourth convolution layer: (32, 1024) -> (64, 1024)\n",
    "        self.conv4 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        # Max pooling operation with a larger downsampling factor\n",
    "        self.pool = nn.MaxPool1d(2)  # Pool by factor of 2\n",
    "\n",
    "        # FC layers for classification (adjusted after the additional convolutions and pooling)\n",
    "        self.fc1 = nn.Linear(256, 32)  # After convolutions and pooling\n",
    "        self.fc2 = nn.Linear(32, num_classes)  # Output layer for classification\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=0.3)  # Dropout for regularization\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)  # Add channel dimension (N, 1024) -> (N, 1, 1024)\n",
    "\n",
    "        # Apply convolutions + ReLU + Pooling\n",
    "        x = self.pool(torch.relu(self.conv1(x)))  # (N, 8, 1024) -> (N, 8, 512)\n",
    "        x = self.pool(torch.relu(self.conv2(x)))  # (N, 16, 512) -> (N, 16, 256)\n",
    "        x = self.pool(torch.relu(self.conv3(x)))  # (N, 32, 256) -> (N, 32, 128)\n",
    "        x = self.pool(torch.relu(self.conv4(x)))  # (N, 64, 128) -> (N, 64, 64)\n",
    "        \n",
    "        # Flatten the tensor before feeding it to the fully connected layer\n",
    "        x = x.view(x.size(0), -1)  # Flatten (N, 64, 64) -> (N, 64 * 64)\n",
    "        \n",
    "        # Apply the fully connected layers\n",
    "        x = self.dropout(torch.relu(self.fc1(x)))  # FC1 + ReLU + Dropout\n",
    "        x = self.fc2(x)  # Output layer\n",
    "        return x\n",
    "\n",
    "model = EEGClassifier(num_classes=len(np.unique(codes)))  # Adjust num_classes based on your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize TensorBoard\n",
    "writer = SummaryWriter('runs/EEG_classification')\n",
    "\n",
    "# Initialize the model, criterion, and optimizer\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, epochs=10):\n",
    "    model.train()\n",
    "    global_step = 0  # To keep track of steps for TensorBoard logging\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        train_loss = 0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        \n",
    "        # Training phase\n",
    "        for eeg_batch, code_batch in train_loader:\n",
    "            eeg_batch, code_batch = eeg_batch.to(device), code_batch.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(eeg_batch)  # Forward pass\n",
    "            loss = criterion(outputs, code_batch)\n",
    "            loss.backward()  # Backpropagation\n",
    "            optimizer.step()  # Optimizer step\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            train_correct += (predicted == code_batch).sum().item()\n",
    "            train_total += code_batch.size(0)\n",
    "            \n",
    "            # TensorBoard: Log every 10 steps\n",
    "            if global_step % 10 == 0:\n",
    "                writer.add_scalar('Training Loss', loss.item(), global_step)\n",
    "                writer.add_scalar('Training Accuracy', (predicted == code_batch).sum().item() / code_batch.size(0), global_step)\n",
    "                \n",
    "            global_step += 1\n",
    "        \n",
    "        # Calculate average loss and accuracy for training set\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        train_accuracy = train_correct / train_total\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for eeg_batch, code_batch in val_loader:\n",
    "                eeg_batch, code_batch = eeg_batch.to(device), code_batch.to(device)\n",
    "                outputs = model(eeg_batch)\n",
    "                loss = criterion(outputs, code_batch)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                val_correct += (predicted == code_batch).sum().item()\n",
    "                val_total += code_batch.size(0)\n",
    "                \n",
    "        # Calculate average loss and accuracy for validation set\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        val_accuracy = val_correct / val_total\n",
    "        \n",
    "        # Log to TensorBoard\n",
    "        writer.add_scalar('Validation Loss', avg_val_loss, epoch)\n",
    "        writer.add_scalar('Validation Accuracy', val_accuracy, epoch)\n",
    "        \n",
    "        # Print results\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}]\")\n",
    "        print(f\"Train Loss: {avg_train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}\")\n",
    "        print(f\"Validation Loss: {avg_val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
    "    \n",
    "    writer.close()  # Close the TensorBoard writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(model, train_loader, val_loader, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "noise_input = torch.randn((1, 1024))  # or shape (1, 513) after FFT\n",
    "model.eval()\n",
    "output = model(noise_input.to(device))\n",
    "print(torch.softmax(output, dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
